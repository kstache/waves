#! /usr/bin/env python

import pathlib

import waves

from eabm_package.python.single_element_compression_mesh_convergence import parameter_schema

# Inherit the parent construction environment
Import('env')

# Comment used in tutorial code snippets: marker-1

# Set project-wide paths with os-agnostic path separators
project_dir = pathlib.Path(env['project_dir'])
abaqus_source_dir = env['abaqus_source_dir']
abaqus_source_abspath = project_dir / abaqus_source_dir
python_source_dir = env['python_source_dir']
python_source_abspath = project_dir / python_source_dir

# Simulation variables
build_directory = pathlib.Path(Dir('.').abspath)
output_file_type = "h5"
parameter_study_file = build_directory / f"parameter_study.{output_file_type}"
previous_parameter_study = str(parameter_study_file) if parameter_study_file.exists() else None
model = "single_element"
simulation_constants = {
    'width': 1.0,
    'height': 1.0,
    'displacement': -0.1
}

# Collect the target nodes to build a concise alias for all targets
workflow = []
datacheck = []

# Comment used in tutorial code snippets: marker-2

# Parameter Study with Cartesian Product
parameter_generator = waves.parameter_generators.CartesianProduct(
    parameter_schema,
    output_file=parameter_study_file,
    output_file_type=output_file_type,
    previous_parameter_study=previous_parameter_study)
parameter_generator.generate()
parameter_study = parameter_generator.parameter_study

# TODO: Find a way to write the parameter study without a user-custom Python build function
def write_parameter_study(target, source, env):
    """`SCons Python build function`_ wrapper for the parameter generator's write() function.

    Reference: https://scons.org/doc/production/HTML/scons-user/ch17s04.html
    """
    parameter_generator.write()
    return None

workflow.extend(env.Command(
    target=[parameter_study_file.name],
    source=[str(python_source_abspath / "single_element_compression_cartesian_product.py")],
    action=[write_parameter_study]))

# Comment used in tutorial code snippets: marker-3

# Geometry
journal_file = f"{model}_geometry"
journal_options = f"--width {simulation_constants['width']} --height {simulation_constants['height']}"
workflow.extend(env.AbaqusJournal(
    target=[f"{journal_file}.cae",
            f"{journal_file}.jnl"],
    source=[f"{abaqus_source_abspath / journal_file}.py"],
    journal_options=journal_options))

# Partition
journal_file = f"{model}_partition"
journal_options = f"--width {simulation_constants['width']} --height {simulation_constants['height']}"
partition_targets = env.AbaqusJournal(
    target=[f"{journal_file}.cae",
            f"{journal_file}.jnl"],
    source=[f"{abaqus_source_abspath / journal_file}.py",
            f"{model}_geometry.cae"],
    journal_options=journal_options)
workflow.extend(partition_targets)
partition_cae_object = partition_targets[0]
partition_cae_file = pathlib.Path(partition_cae_object.abspath)

# Parameterized targets must live inside current simulation_variables for loop
for set_name, parameters in parameter_generator.parameter_study.sel(data_type='samples').groupby('parameter_sets'):
    set_name = pathlib.Path(set_name)
    simulation_variables = {**parameters.squeeze().to_array().to_series().to_dict(), **simulation_constants}

    # Comment used in tutorial code snippets: marker-4

    # Mesh
    journal_file = f"{model}_mesh"
    journal_options = f"--global-seed {simulation_variables['global_seed']} " \
        f"--input-file {partition_cae_file.with_suffix('')} " \
        f"--output-file {journal_file}"
    workflow.extend(env.AbaqusJournal(
        target=[f"{set_name / journal_file}.cae",
                f"{set_name / journal_file}.jnl",
                f"{set_name / journal_file}.inp"],
        source=[f"{abaqus_source_abspath / journal_file}.py",
                partition_cae_object],
        journal_options=journal_options))

    # SolverPrep
    abaqus_source_list = [
        f"#/{abaqus_source_dir}/{model}_compression.inp.in",
        f"#/{abaqus_source_dir}/amplitudes.inp",
        f"#/{abaqus_source_dir}/assembly.inp",
        f"#/{abaqus_source_dir}/boundary.inp",
        f"#/{abaqus_source_dir}/field_output.inp",
        f"#/{abaqus_source_dir}/materials.inp",
        f"#/{abaqus_source_dir}/parts.inp",
        f"#/{abaqus_source_dir}/history_output.inp"
    ]
    abaqus_source_list = [pathlib.Path(source_file) for source_file in abaqus_source_list]
    workflow.extend(waves.builders.copy_substitute(
        abaqus_source_list,
        substitution_dictionary=waves.builders.substitution_syntax(simulation_variables),
        build_subdirectory=set_name))

# Comment used in tutorial code snippets: marker-5

    # Abaqus Solve
    solve_source_list = [f"{set_name / source_file.name.rstrip('.in')}" for source_file in abaqus_source_list]
    solve_source_list.append([f"{set_name / journal_file}.inp"])
    job_name = pathlib.Path(solve_source_list[0]).with_suffix('').name
    datacheck_name = f"{job_name}_DATACHECK"
    datacheck_suffixes = ('023', 'mdl', 'sim', 'stt')
    abaqus_options='-double both'
    datacheck.extend(env.AbaqusSolver(
        target=[f"{set_name / datacheck_name}.{suffix}" for suffix in datacheck_suffixes],
        source=solve_source_list,
        job_name=datacheck_name,
        abaqus_options=f'{abaqus_options} -datacheck'))

    workflow.extend(env.AbaqusSolver(
        target=[f"{set_name / job_name}.sta"],
        source=solve_source_list,
        job_name=job_name,
        abaqus_options=abaqus_options))

    # Extract Abaqus
    extract_source_list = [f"{set_name / job_name}.odb"]
    workflow.extend(env.AbaqusExtract(
        target=[f"{set_name / job_name}.h5"],
        source=extract_source_list))

# Comment used in tutorial code snippets: marker-6

# Post-processing
plot_name = "stress_strain_comparison.pdf"
post_processing_source = [f"{pathlib.Path(set_name) / job_name}_datasets.h5" for set_name in parameter_study.parameter_sets.values]
script_options = "--input-file " + " ".join(str(path) for path in post_processing_source)
script_options += f" --output-file {plot_name} --x-units 'mm/mm' --y-units 'MPa'"
script_options += f" --parameter-study-file {parameter_study_file.name}"
workflow.extend(env.PythonScript(
    target=[plot_name],
    source=[f"{python_source_abspath}/plot_scatter.py", parameter_study_file.name] + post_processing_source,
    script_options=script_options))

plot_name = "mesh_convergence_stress.pdf"
selection_dict = '"{\'LE values\': \'LE22\', \'S values\': \'S22\', \'elements\': 1, \'step\': \'Step-1\', \'time\': 1.0}"'
script_options = "--input-file " + " ".join(str(path) for path in post_processing_source)
script_options += f" --output-file {plot_name} --x-units 'mm' --y-units 'MPa' --x-var 'global_seed' --y-var 'S'"
script_options += f" --parameter-study-file {parameter_study_file.name}"
script_options += f" --selection-dict {selection_dict}"
workflow.extend(env.PythonScript(
    target=[plot_name],
    source=[f"{python_source_abspath}/plot_scatter.py", parameter_study_file.name] + post_processing_source,
    script_options=script_options))

# Collector alias based on parent directory name
parent_directory = Dir('.').srcnode().name
env.Alias(parent_directory, workflow)
env.Alias(f"{parent_directory}_datacheck", datacheck)
env.Alias(env['datacheck_alias'], datacheck)

if not env['unconditional_build'] and not env['abaqus']:
    print(f"Program 'abaqus' was not found in construction environment. Ignoring '{parent_directory}' target(s)")
    Ignore(['.', parent_directory], workflow)
    Ignore(['.', model], datacheck)
