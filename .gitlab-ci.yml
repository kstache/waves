workflow:
  rules:  # Do not create pipelines for tag updates
    - if: $CI_COMMIT_TAG
      when: never
    - when: always

stages:
  - environment
  - version
  - test
  - build
  - deploy

before_script:
  # Assumes CI executes on AEA compute servers
  # TODO: recover environment path from modulefile instead of assuming the sstelmo path(s)
  # https://re-git.lanl.gov/aea/python-projects/waves/-/issues/7
  - aea_compute_path="/projects/aea_compute"
  - aea_conda_channel="${aea_compute_path}/aea-conda"
  - aea_modulefiles="${aea_compute_path}/modulefiles"
  - module use ${aea_modulefiles}
  - module load texlive
  - module load sierra
  - module use ${PWD}/modulefiles
  # Prefer the CI environment and fall back to AEA environment(s)
  - project_environment='waves-env'
  - environment_choices="${project_environment} aea-beta aea-release"
  - for env in ${environment_choices}; do if [[ -d "${aea_compute_path}/${env}" ]]; then environment=${env}; break; fi; done
  - echo ${environment}
  - module load ${environment}
  - conda info
  # TODO: kick off 'environment' job for missing environments instead of re-creating the environment build logic here
  # https://re-git.lanl.gov/aea/python-projects/waves/-/issues/8
  - environment_path="${aea_compute_path}/${project_environment}"
  - conda_options='--force'
  - |
      if [[ ! -d ${environment_path} ]]; then
          export ALL_PROXY="proxyout.lanl.gov:8080"
          export HTTP_PROXY="http://$ALL_PROXY"
          export HTTPS_PROXY=$HTTP_PROXY
          conda env create --prefix ${environment_path} --file environment.yml ${conda_options};
          chmod -R 755 ${environment_path}
          unset ALL_PROXY
          unset HTTP_PROXY
          unset HTTPS_PROXY
      fi
  - if [[ ${project_environment} != ${environment} ]]; then module unload ${environment}; module load ${project_environment}; fi
  - conda_artifacts_directory='conda-bld'

environment:
  stage: environment
  variables:
    GIT_STRATEGY: clone
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" || $CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "dev"
      changes:
        - "modulefiles/*"
        - "environment.yml"
  script:
    # Set LANL proxies
    - export ALL_PROXY="proxyout.lanl.gov:8080"
    - export HTTP_PROXY="http://$ALL_PROXY"
    - export HTTPS_PROXY=$HTTP_PROXY
    # Re-build the Conda environment on changes to environment files
    - conda env create --prefix ${environment_path} --file environment.yml ${conda_options}
    # Remove write permissions from group to avoid accidental environment changes
    - chmod -R 755 ${environment_path}
    # place the common modulefiles in an accessible location
    - cp ${PWD}/modulefiles/* ${aea_modulefiles}
    # Link SCons man pages to the expected MANPATH location
    - ln ${environment_path}/scons.1 ${environment_path}/man/man1/scons.1
    - ln ${environment_path}/sconsign.1 ${environment_path}/man/man1/sconsign.1
    - ln ${environment_path}/scons-time.1 ${environment_path}/man/man1/scons-time.1
  tags:
    - shell-aea

microbump:
  stage: version
  variables:
    GIT_STRATEGY: clone
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: never
    - if: $CI_COMMIT_BRANCH == "main"
  script:
    # Conditionally "bump" micro version number. setuptools_scm already bumps number, just need to strip local version.
    - old_version=$(python -m setuptools_scm)
    # First capture group is the major.minor.micro numbers
    # Second capture group is everything following micro
    - version_regex='\([0-9]\+\.[0-9]\+\.[0-9]\+\)\(.*\)'
    # Returns clean production tag regardless if tagged already
    - production_version=$(echo ${old_version} | sed "s/${version_regex}/\1/g")
    # Catch unexpected production version regex and exit with error if suffix is found
    - suffix=$(echo ${production_version} | sed "s/${version_regex}/\2/g")
    - |
        if [ -n "${suffix}" ]; then
            echo "Could not resolve the production version from ${old_version}. Left with ${production_version} and ${suffix}."
            exit 1
        fi
    - developer_version=${production_version}+dev
    # Tag production commit and previous developer commit. Continue if already tagged.
    - git config user.name "${GITLAB_USER_NAME}"
    - git config user.email "${GITLAB_USER_EMAIL}"
    - git remote add oauth2-origin https://gitlab-ci-token:${GITLAB_ACCESS_TOKEN}@re-git.lanl.gov/${CI_PROJECT_PATH}.git
    - git tag -a ${production_version} -m "production release ${production_version}" || true
    # Assume last merge was dev->main. Pick previous.
    - last_merge_hash=$(git log --pretty=format:"%H" --merges -n 2 | tail -n 1)
    - git tag -a ${developer_version} -m "developer pre-release ${developer_version}" ${last_merge_hash} || true
    - git push oauth2-origin --tags
  tags:
    - shell-aea

fast-test:
  stage: test
  variables:
    GIT_STRATEGY: clone
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
  script:
    - project_root=${PWD}
    # Project unit tests
    - scons . --keep-going --unconditional-build --cov-report
    # Set PYTHONPATH for WAVES import in tutorials/quickstart system/integration/regression tests
    - export PYTHONPATH=${project_root}:$PYTHONPATH
    # WAVES CLI regression tests
    - quickstart_regression_directory="${project_root}/test_quickstart"
    - python -m waves.main quickstart ${quickstart_regression_directory}
    - cd ${quickstart_regression_directory}
    - scons . --jobs=4
    - cd ${project_root}
    - python -m waves.main visualize nominal --sconstruct ${quickstart_regression_directory}/SConstruct --output-file ${quickstart_regression_directory}/nominal.svg
    # Regression test the files used in the tutorial documentation
    - tutorials_regression_directory="${project_root}/test_tutorials"
    - python -m waves.main fetch tutorials --destination ${tutorials_regression_directory}
    - cd ${tutorials_regression_directory}
    - python -m waves.main build --max-iterations=4 tutorial_extend_study --sconstruct=tutorial_extend_study_SConstruct --jobs=4
    - cd ${project_root}
  coverage: '/(?i)total.*? (100(?:\.0+)?\%|[1-9]?\d(?:\.\d+)?\%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
  tags:
    - shell-aea

conda-build:
  stage: build
  variables:
    GIT_STRATEGY: clone
  dependencies: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "dev"
  script:
    # Set the LANL internal proxies
    - export ALL_PROXY="proxyout.lanl.gov:8080"
    - export HTTP_PROXY="http://$ALL_PROXY"
    - export HTTPS_PROXY=$HTTP_PROXY
    # Override default permissions. Set group to rx with no write permissions.
    - umask 0022
    - mkdir ${conda_artifacts_directory}
    - croot="/scratch/$USER/$(basename $PWD)/${conda_artifacts_directory}"
    - VERSION=$(python -m setuptools_scm) mamba build recipe-internal --channel conda-forge --no-anaconda-upload --croot ${croot} --output-folder ${conda_artifacts_directory}
    - mamba build purge --croot ${croot}
  artifacts:
    expire_in: '2 hrs'
    paths:
      - conda-bld/noarch/waves-*-*.tar.bz2
  tags:
    - shell-aea

deploy:
  stage: deploy
  variables:
    GIT_STRATEGY: clone
  dependencies:
    - conda-build
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: never
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "dev"
  script:
    # Override default permissions. Set group to rx with no write permissions.
    - umask 0022
    # Copy Conda package to AEA Conda Channel
    - cp ${conda_artifacts_directory}/noarch/waves-*-*.tar.bz2 ${aea_conda_channel}/noarch
    # Change group for access by all W-13 staff and prevent accidental modification by institutional account in CI jobs
    - chgrp w13users ${aea_conda_channel}/noarch/waves-*-*.tar.bz2 || true
    - chmod 555 ${aea_conda_channel}/noarch/waves-*-*.tar.bz2 || true
    # Update the AEA Conda Channel index
    - conda index ${aea_conda_channel}
    # Troubleshooting conda channel deploy and index update
    - conda search --channel file://${aea_conda_channel}/ --override-channels waves
  tags:
    - shell-aea

# It MUST be called pages
pages:
  stage: deploy
  variables:
    GIT_STRATEGY: clone
  dependencies: []
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
      when: never
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "dev"
  script:
    # Set job-wide variables and directories
    - project_root=$PWD
    - rm -rf public && mkdir -p public
    - cp docs/_static/index.html public
    # Every documentation version must be re-built for *every* gitlab-pages job execution
    # Reference: https://gitlab.com/gitlab-org/gitlab/-/issues/33822
    - git fetch origin
    - git branch -a
    - documentation_branches="main dev"
    - |
        for ref in ${documentation_branches}; do
            cd ${project_root}
            git checkout $ref
            git reset --hard origin/$ref
            mkdir -p public/$ref/waves-eabm
            # Build WAVES HTML documentation. Clean up after to avoid leftover targets from main/dev filename differences.
            # Clean instead of "rm" to help catch incomplete target clean operations.
            scons . --clean --unconditional-build
            scons html-internal --unconditional-build
            cp -r build/docs/html-internal/* ${project_root}/public/$ref
            scons . --clean --unconditional-build
            # Build WAVES-EABM HTML documentation
            cd quickstart
            PYTHONPATH=${project_root} scons . --clean
            PYTHONPATH=${project_root} scons html
            cp -r build/docs/html/* ${project_root}/public/$ref/waves-eabm
            PYTHONPATH=${project_root} scons . --clean
            cd ${project_root}
        done
  artifacts:
    paths:
      # It MUST be called public
      - public
  tags:
    - shell-aea
